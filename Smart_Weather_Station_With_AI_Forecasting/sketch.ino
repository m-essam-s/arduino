#include <WiFi.h> // This library allows the ESP32 to connect to a WiFi network. It is built into the Arduino IDE for ESP32 boards.
#include <DHT.h> // This library enables communication with a DHT temperature and humidity sensor (DHT11/DHT22).
#include "TensorFlowLite.h" // This library provides support for running TensorFlow Lite models on microcontrollers like the ESP32.

// Replace with your network credentials
#define ssid "your_network_name" // Network SSID (name)
#define password "your_network_password" // Network password

#define DHTPIN 4 // Digital pin connected to the DHT sensor
#define DHTTYPE DHT22 // DHT sensor type if you are using DHT11, change this to DHT11
DHT dht(DHTPIN, DHTTYPE); // Create a DHT object to read from the sensor

// TensorFlow Lite model configuration
#include "weather_model_tflite.h" // This header file contains the TensorFlow Lite model.
const tflite::Model *model; // Represents the TensorFlow Lite model
tflite::MicroInterpreter *interpreter; // The interpreter runs the model by allocating memory, setting up input and output tensors, and invoking the model. It acts as the interface to execute inference on the model.
tflite::ErrorReporter *error_reporter; // Captures and reports errors during initialization or inference (e.g., invalid model structure, memory issues).
tflite::MicroMutableOpResolver<2> resolver; //  indicates that 2 TensorFlow Lite operators will be registered (AddFullyConnected() and AddSoftmax() in the setup).
constexpr int tensor_arena_size = 2 * 1024; // Here, 2 KB (2 * 1024) is allocated, which should be adjusted based on your specific model. If the arena size is too small, the model will fail to run.
uint8_t tensor_arena[tensor_arena_size]; // Ablockof memory used by the TensorFlow Lite interpreter to store:

// input and output tensors

TfLiteTensor *input; // Represents the data that is fed into the model for inference (e.g., temperature and humidity values).
TfLiteTensor *output; // Represents the predictions generated by the model.

// Function to initialize the TensorFlow Lite model
void init_model(){
    // Set up the model
    model = tflite::GetModel(weather_model_tflite); // This retrieves the TensorFlow Lite model and loads it into memory. 
    if (model->version() != TFLITE_SCHEMA_VERSION){  // Check if the model schema version is supported by the interpreter.
        Serial.print("Model provided is schema version is not supported by this interpreter"); // If the schema version is not supported, an error message is printed.
        return; // The function returns without proceeding further.
    } 
    resolver.AddFullyConnected(); // Add the fully connected layer to the resolver.
    resolver.AddSoftmax(); // Add the softmax layer to the resolver.
    static tflite::MicroErrorReporter micro_error_reporter; // Initializes an error reporter (micro_error_reporter) that logs errors during model initialization or execution.
    error_reporter = &micro_error_reporter; 
    static tflite::MicroInterpreter static_interpreter(model, resolver, tensor_arena, tensor_arena_size, error_reporter);
    /* Instantiates a MicroInterpreter object using:
            o Theloaded model.
            o Theresolver (which knows the required operators).
            o Thetensor arena (allocated memory for the model’s computations).
            o Theerror reporter (for logging issues). */
    interpreter = &static_interpreter;
    TfLiteStatus allocate_status = interpreter->AllocateTensors();
    /*  Allocates memory for:
            o Input tensors (to store data fed into the model).
            o Output tensors (to store results from the model).
            o Intermediate tensors (for calculations during inference). */
    if (allocate_status != kTfLiteOk){ // Checks if memory allocation was successful.
        Serial.print("Error allocating tensors"); // If memory allocation fails, an error message is printed.
        return; // The function returns without proceeding further.
    }  
    input = interpreter->input(0);
    output = interpreter->output(0);
}

// Function to get the weather prediction
// input: temperature and humidity values
String predictWeatherAI(float temperature, float humidity){
    // Set the input tensor
    input->data.f[0] = temperature; // Represents the first input, which is the temperature.
    input->data.f[1] = humidity;    // Represents the second input, which is the humidity.

    // Run inference
    if (interpreter->Invoke() != kTfLiteOk) 
        // Invokes the model to run inference. If the invocation fails, an error message is printed.
    {
        Serial.print("Error invoking the model");
        return "Error"; // The function returns an error message.
    }

    // Get Prediction
    float prediction[3]; // An array to store the prediction values (Sunny, Rainy, Cloudy).
    for (int i = 0; i < 3; i++){ // Iterates over the output tensor to get the prediction values.
        prediction[i] = output->data.f[i]; // Stores the prediction values in the array.
    } 

    // Find the index of the maximum value
    int max_index = 0; // Initializes a variable to store the index of the maximum prediction value.
    for (int i = 1; i < 3; i++){ // Iterates over the prediction array to find the index of the maximum value.
        if (prediction[i] > prediction[max_index]){ // Compares the current prediction value with the maximum prediction value.
            max_index = i; // Updates the index of the maximum prediction value if a higher value is found.
        }
    }

    // Return the prediction
     // Checks the index of the maximum prediction value and returns the corresponding weather condition.
    switch (max_index){
    case 0:
        return "Sunny"; 
    case 1:
        return "Rainy";
    case 2:
        return "Cloudy";
    default:
        return "Error";
    }
    
}

void setup(){
    // Initialize Serial Monitor
    Serial.begin(115200); // This initializes the serial communication at a baud rate of 115200.
    WiFi.begin(ssid, password); // This connects the ESP32 to the specified WiFi network using the provided SSID and password.

    while (WiFi.status() != WL_CONNECTED){ // This loop checks if the ESP32 is connected to the WiFi network.
        delay(1000);
        Serial.println("Connecting to WiFi...");
    }
    Serial.println("Connected to the WiFi network");
    


    // Initialize DHT sensor
    dht.begin(); // This initializes the DHT sensor.

    // Initialize the TensorFlow Lite model
    init_model(); // This function initializes the TensorFlow Lite model for weather prediction.
}

void loop(){
    // Read temperature and humidity
    float temperature = dht.readTemperature(); // This reads the temperature from the DHT sensor.
    float humidity = dht.readHumidity(); // This reads the humidity from the DHT sensor.

    // Check if any reads failed and exit early
    if (isnan(temperature) || isnan(humidity)){ // This checks if the temperature or humidity readings are invalid (e.g., NaN).
        Serial.println("Failed to read from DHT sensor!");
        return;
    }

    // Get the weather prediction
    String forcast = predictWeatherAI(temperature, humidity); // This function call uses the TensorFlow Lite model to predict the weather based on temperature and humidity.
    Serial.print("Temperature: " + String(temperature) + "°C"); // This prints the temperature and humidity readings along with the predicted weather condition.
    Serial.print("Humidity: " + String(humidity) + "%"); // This prints the temperature and humidity readings along with the predicted weather condition.
    Serial.print("Weather: " + forcast); // This prints the temperature and humidity readings along with the predicted weather condition.

    delay(2000); // This introduces a delay of 2 seconds before the next iteration.
}
